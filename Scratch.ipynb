{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring Color to Greyscale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import image\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "figsize(16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30113\n"
     ]
    }
   ],
   "source": [
    "import convnets\n",
    "import train\n",
    "reload(convnets)\n",
    "reload(train)\n",
    "\n",
    "SIZE = 100\n",
    "IMDIR = \"images/raw\"\n",
    "\n",
    "handles = [os.path.join(IMDIR, h) for h in os.listdir(IMDIR)]\n",
    "print len(handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseLayer (None, 100) => (None, 6)\n",
      "DenseLayer (None, 5, 23, 23) => (None, 100)\n",
      "MaxPool2DLayer (None, 5, 46, 46) => (None, 5, 23, 23)\n",
      "Conv2DLayer (None, 12, 48, 48) => (None, 5, 46, 46)\n",
      "MaxPool2DLayer (None, 12, 96, 96) => (None, 12, 48, 48)\n",
      "Conv2DLayer (None, 1, 100, 100) => (None, 12, 96, 96)\n",
      "DimshuffleLayer (None, 100, 100) => (None, 1, 100, 100)\n",
      "InputLayer  => (None, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "base = convnets.COLOR_STATS_NET\n",
    "theano_exprs = convnets.CreateTheanoExprs(\n",
    "    base_net=base,\n",
    "    height=SIZE,\n",
    "    width=SIZE,\n",
    "    learning_rate=0.001)\n",
    "net, train_fn, val_fn, prediction, target_var, transformed_target = theano_exprs[:6]\n",
    "convnets.PrintNetworkShape(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation and testing images...\n",
      "Starting training...\n",
      "Training batch 0 of 500 images. Last time = 0.00 seconds. Last load time = 6.17 seconds. Last error = 1.00000.\n",
      "Training batch 1 of 500 images. Last time = 5.07 seconds. Last load time = 7.91 seconds. Last error = 0.68587.\n",
      "Training batch 2 of 500 images. Last time = 6.69 seconds. Last load time = 8.67 seconds. Last error = 0.64417.\n",
      "Training batch 3 of 500 images. Last time = 5.34 seconds. Last load time = 7.45 seconds. Last error = 0.63587.\n",
      "\n",
      "Validating...\n",
      "Validated on 500 images in 1.75 seconds. Error = 0.56544.\n",
      "\n",
      "Training batch 4 of 500 images. Last time = 5.38 seconds. Last load time = 7.74 seconds. Last error = 0.62765.\n",
      "Training batch 5 of 500 images. Last time = 5.31 seconds. Last load time = 7.36 seconds. Last error = 0.61942.\n",
      "Training batch 6 of 500 images. Last time = 5.48 seconds. Last load time = 7.62 seconds. Last error = 0.61144.\n",
      "Training batch 7 of 500 images. Last time = 5.35 seconds. Last load time = 7.45 seconds. Last error = 0.60438.\n",
      "\n",
      "Validating...\n",
      "Validated on 500 images in 1.70 seconds. Error = 0.55260.\n",
      "\n",
      "Training batch 8 of 500 images. Last time = 5.40 seconds. Last load time = 7.70 seconds. Last error = 0.59709.\n",
      "Training batch 9 of 500 images. Last time = 6.14 seconds. Last load time = 8.18 seconds. Last error = 0.58990.\n",
      "Training batch 10 of 500 images. Last time = 5.32 seconds. Last load time = 7.35 seconds. Last error = 0.58271.\n",
      "Training batch 11 of 500 images. Last time = 5.22 seconds. Last load time = 7.79 seconds. Last error = 0.57538.\n",
      "\n",
      "Validating...\n",
      "Validated on 500 images in 1.69 seconds. Error = 0.53432.\n",
      "\n",
      "Training batch 12 of 500 images. Last time = 6.00 seconds. Last load time = 8.27 seconds. Last error = 0.56763.\n",
      "Training batch 13 of 500 images. Last time = 6.77 seconds. Last load time = 9.09 seconds. Last error = 0.55998.\n",
      "Training batch 14 of 500 images. Last time = 5.44 seconds. Last load time = 7.58 seconds. Last error = 0.55253.\n",
      "Training batch 15 of 500 images. Last time = 5.33 seconds. Last load time = 7.35 seconds. Last error = 0.54556.\n",
      "\n",
      "Validating...\n",
      "Validated on 500 images in 1.67 seconds. Error = 0.51602.\n",
      "\n",
      "Training batch 16 of 500 images. Last time = 5.33 seconds. Last load time = 7.56 seconds. Last error = 0.53906.\n",
      "Training batch 17 of 500 images. Last time = 5.21 seconds. Last load time = 7.26 seconds. Last error = 0.53300.\n",
      "Training batch 18 of 500 images. Last time = 6.25 seconds. Last load time = 8.33 seconds. Last error = 0.52714.\n",
      "Training batch 19 of 500 images. Last time = 5.46 seconds. Last load time = 7.54 seconds. Last error = 0.52156.\n",
      "\n",
      "Validating...\n",
      "Validated on 500 images in 1.79 seconds. Error = 0.50475.\n",
      "\n",
      "\n",
      "Testing...\n",
      "Tested on 500 images in 1.53 seconds. Error = 0.5984.\n"
     ]
    }
   ],
   "source": [
    "batch_stats, val_stats, err, net  = train.Train(\n",
    "    num_batches=20,\n",
    "    validate_every_n_batches=4,\n",
    "    height=SIZE,\n",
    "    width=SIZE,\n",
    "    batch_size=500,\n",
    "    image_handles=handles,\n",
    "    val_set_size=500,\n",
    "    test_set_size=500,\n",
    "    net=net,\n",
    "    train_fn=train_fn,\n",
    "    val_fn=val_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.zeros((100, SIZE, SIZE, 3))\n",
    "train.LoadImages(handles, SIZE, SIZE, 100, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ImStat(images):\n",
    "    for i, color in enumerate([\"  red\", \"green\", \" blue\"]):\n",
    "        channel = images[:, :, :, i]\n",
    "        print \"{c}: mean={m:.2f}, std={s:.2f}\".format(\n",
    "            c=color, m=channel.mean(), s=channel.std())\n",
    "    grey = (images[:, :, :, 0] * 0.299 +\n",
    "            images[:, :, :, 1] * 0.587 +\n",
    "            images[:, :, :, 2] * 0.114)\n",
    "    print \" grey: mean={m:.2f}, std={s:.2f}\".format(\n",
    "        m=grey.mean(), s=grey.std())\n",
    "    \n",
    "    sh = images.shape\n",
    "    rsh = (sh[0], sh[1] * sh[2], sh[3])\n",
    "    ch = images.reshape(rsh)\n",
    "    means = ch.mean(axis=1)\n",
    "    stds = ch.std(axis=1)\n",
    "    print \"Mean of Means:\", means.mean(axis=0)\n",
    "    print \" Std of Means:\", means.std(axis=0)\n",
    "    print \" Mean of Stds:\", stds.mean(axis=0)\n",
    "    print \"  Std of Stds:\", stds.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  red: mean=126.99, std=69.70\n",
      "green: mean=136.61, std=67.88\n",
      " blue: mean=148.99, std=73.16\n",
      " grey: mean=135.15, std=66.31\n",
      "Mean of Means: [ 126.989014  136.610888  148.994259]\n",
      " Std of Means: [ 39.63258256  39.60512887  46.70437152]\n",
      " Mean of Stds: [ 54.71197316  52.48722761  53.37689392]\n",
      "  Std of Stds: [ 17.12463232  16.8657054   17.94935142]\n"
     ]
    }
   ],
   "source": [
    "ImStat(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = train.Evaluator(prediction, target_var, transformed_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.24561741, -0.09533195, -0.2080202 ,  0.21776753, -0.26968742,\n",
       "         -0.19626031]]),\n",
       " array([[ 0.38071619, -0.42554809, -1.30481532, -1.46501344, -0.94421481,\n",
       "         -0.29198509]])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(images[np.random.randint(0, len(images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
